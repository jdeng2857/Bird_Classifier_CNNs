{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5392d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 11:52:39.322177: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-02 11:52:40.115535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a67bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, use_rows, batch_size, csv_file=\"birds.csv\"):\n",
    "        self.csv_df = pd.read_csv(csv_file)\n",
    "        self.use_rows = use_rows\n",
    "        self.batch_size = batch_size \n",
    "        self.dataset = pd.DataFrame(self.csv_df).to_numpy()\n",
    "    \n",
    "        self.labels = self.dataset[:,2]\n",
    "        self.img_filepaths = self.dataset[:,1]\n",
    "        self.class_ids = self.dataset[:,0]\n",
    "        \n",
    "        (x,) = self.img_filepaths.shape\n",
    "        print(self.dataset.shape)\n",
    "        print(self.img_filepaths[0])\n",
    "        image = Image.open(self.img_filepaths[0])\n",
    "        image_array = np.expand_dims(np.asarray(image), axis=0)\n",
    "        \n",
    "#         print(image_array)\n",
    "        print(image_array.shape)\n",
    "        \n",
    "#         self.images = []\n",
    "        \n",
    "#         for i in range(0, 10):\n",
    "#             image = Image.open(self.img_filepaths[0])\n",
    "#             image_array = np.expand_dims(np.asarray(image), axis=0)\n",
    "#             self.images.append(image_array)\n",
    "            \n",
    "#         self.images = np.array(self.images)\n",
    "        \n",
    "#         print(self.images.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # batches_per_epoch is the total number of batches used for one epoch\n",
    "        batches_per_epoch = int(len(self.use_rows) / self.batch_size)\n",
    "        return batches_per_epoch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # index is the index of the batch to be retrieved\n",
    "        batch_ids = self.use_rows[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        \n",
    "        x = None\n",
    "        y = None\n",
    "        \n",
    "#         print(\"batch index: \"+str(index))\n",
    "#         print(\"batch ids: \" + str(batch_ids))\n",
    "        \n",
    "        for curr_id in batch_ids:\n",
    "            image = Image.open(self.img_filepaths[curr_id]).resize((224,224))\n",
    "#             image = image.convert(\"L\")\n",
    "#             np_row = np.asarray(image)\n",
    "            image_array = np.expand_dims(np.asarray(image),axis=0)\n",
    "            \n",
    "            if x is None:\n",
    "                x = image_array\n",
    "                y = self.class_ids[curr_id]\n",
    "            else:\n",
    "                x = np.vstack((x, image_array))\n",
    "                y = np.vstack((y, self.class_ids[curr_id]))\n",
    "                \n",
    "    \n",
    "#             print(self.class_ids[curr_id-1])\n",
    "            \n",
    "        \n",
    "#         images = np.array(images)\n",
    "#         id_labels = np.array(id_labels)\n",
    "#         print(id_labels)\n",
    "#         print(images.shape)\n",
    "#         print(id_labels.shape)\n",
    "#         print(self.class_ids)\n",
    "        \n",
    "#         print(self.class_ids.shape)\n",
    "        \n",
    "        \n",
    "        y = tf.keras.utils.to_categorical(y, num_classes=511)\n",
    "#         print(x.shape)\n",
    "#         print(y.shape)\n",
    "        return x, y            \n",
    "            \n",
    "#     def on_epoch_end(self):\n",
    "#         np.random.shuffle(self.split_ids)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43122b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87050, 5)\n",
      "train/ABBOTTS BABBLER/001.jpg\n",
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[180, 172, 149],\n",
       "          [186, 178, 155],\n",
       "          [186, 180, 158],\n",
       "          ...,\n",
       "          [181, 180, 198],\n",
       "          [179, 180, 200],\n",
       "          [178, 179, 199]],\n",
       " \n",
       "         [[182, 174, 153],\n",
       "          [190, 182, 161],\n",
       "          [190, 184, 162],\n",
       "          ...,\n",
       "          [182, 181, 199],\n",
       "          [176, 177, 197],\n",
       "          [178, 179, 199]],\n",
       " \n",
       "         [[186, 178, 159],\n",
       "          [195, 187, 168],\n",
       "          [196, 189, 170],\n",
       "          ...,\n",
       "          [184, 183, 199],\n",
       "          [180, 179, 197],\n",
       "          [183, 182, 200]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[151, 138, 121],\n",
       "          [172, 159, 142],\n",
       "          [178, 165, 146],\n",
       "          ...,\n",
       "          [189, 190, 211],\n",
       "          [191, 189, 210],\n",
       "          [169, 167, 188]],\n",
       " \n",
       "         [[156, 140, 124],\n",
       "          [155, 139, 123],\n",
       "          [161, 148, 131],\n",
       "          ...,\n",
       "          [186, 188, 211],\n",
       "          [182, 185, 204],\n",
       "          [168, 171, 188]],\n",
       " \n",
       "         [[157, 141, 125],\n",
       "          [156, 140, 124],\n",
       "          [167, 154, 137],\n",
       "          ...,\n",
       "          [169, 174, 196],\n",
       "          [181, 186, 205],\n",
       "          [147, 153, 169]]],\n",
       " \n",
       " \n",
       "        [[[ 37,  62,  33],\n",
       "          [ 39,  64,  35],\n",
       "          [ 39,  62,  34],\n",
       "          ...,\n",
       "          [ 51,  82,  50],\n",
       "          [ 52,  82,  48],\n",
       "          [ 54,  84,  50]],\n",
       " \n",
       "         [[ 37,  62,  33],\n",
       "          [ 39,  64,  35],\n",
       "          [ 39,  62,  34],\n",
       "          ...,\n",
       "          [ 53,  84,  52],\n",
       "          [ 53,  83,  49],\n",
       "          [ 53,  83,  49]],\n",
       " \n",
       "         [[ 38,  63,  34],\n",
       "          [ 39,  64,  35],\n",
       "          [ 38,  63,  34],\n",
       "          ...,\n",
       "          [ 55,  86,  54],\n",
       "          [ 54,  84,  50],\n",
       "          [ 53,  83,  49]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[154, 128, 111],\n",
       "          [123,  96,  79],\n",
       "          [ 87,  55,  44],\n",
       "          ...,\n",
       "          [ 60,  87,  78],\n",
       "          [ 58,  85,  76],\n",
       "          [ 56,  83,  74]],\n",
       " \n",
       "         [[108,  76,  63],\n",
       "          [ 85,  52,  43],\n",
       "          [111,  77,  75],\n",
       "          ...,\n",
       "          [ 60,  87,  78],\n",
       "          [ 59,  85,  76],\n",
       "          [ 57,  83,  74]],\n",
       " \n",
       "         [[122,  88,  78],\n",
       "          [160, 125, 119],\n",
       "          [187, 153, 154],\n",
       "          ...,\n",
       "          [ 60,  87,  78],\n",
       "          [ 60,  86,  77],\n",
       "          [ 58,  84,  75]]],\n",
       " \n",
       " \n",
       "        [[[238, 238, 230],\n",
       "          [237, 237, 229],\n",
       "          [238, 238, 228],\n",
       "          ...,\n",
       "          [ 89,  77,  65],\n",
       "          [ 83,  71,  57],\n",
       "          [ 80,  68,  52]],\n",
       " \n",
       "         [[238, 238, 230],\n",
       "          [237, 237, 229],\n",
       "          [238, 238, 228],\n",
       "          ...,\n",
       "          [ 81,  69,  57],\n",
       "          [ 83,  71,  57],\n",
       "          [ 86,  74,  60]],\n",
       " \n",
       "         [[237, 237, 227],\n",
       "          [236, 236, 226],\n",
       "          [237, 237, 227],\n",
       "          ...,\n",
       "          [ 82,  70,  56],\n",
       "          [ 87,  75,  63],\n",
       "          [ 83,  71,  59]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 99, 138,  29],\n",
       "          [111, 148,  42],\n",
       "          [114, 149,  47],\n",
       "          ...,\n",
       "          [ 39,  39,  37],\n",
       "          [ 44,  44,  44],\n",
       "          [ 44,  44,  44]],\n",
       " \n",
       "         [[106, 145,  38],\n",
       "          [122, 159,  54],\n",
       "          [108, 143,  43],\n",
       "          ...,\n",
       "          [ 41,  43,  40],\n",
       "          [ 46,  46,  46],\n",
       "          [ 44,  44,  44]],\n",
       " \n",
       "         [[107, 146,  39],\n",
       "          [112, 149,  44],\n",
       "          [118, 152,  55],\n",
       "          ...,\n",
       "          [ 41,  43,  38],\n",
       "          [ 46,  46,  46],\n",
       "          [ 42,  42,  42]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          ...,\n",
       "          [ 71,  62,  55],\n",
       "          [ 70,  61,  54],\n",
       "          [ 70,  61,  54]],\n",
       " \n",
       "         [[ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          ...,\n",
       "          [ 70,  61,  54],\n",
       "          [ 70,  61,  54],\n",
       "          [ 70,  61,  54]],\n",
       " \n",
       "         [[ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          ...,\n",
       "          [ 70,  61,  54],\n",
       "          [ 69,  60,  53],\n",
       "          [ 69,  60,  53]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 97,  91,  79],\n",
       "          [ 98,  92,  80],\n",
       "          [106, 100,  88],\n",
       "          ...,\n",
       "          [ 49,  48,  46],\n",
       "          [ 49,  48,  46],\n",
       "          [ 49,  48,  46]],\n",
       " \n",
       "         [[152, 146, 134],\n",
       "          [149, 143, 131],\n",
       "          [150, 144, 132],\n",
       "          ...,\n",
       "          [ 50,  49,  47],\n",
       "          [ 50,  49,  47],\n",
       "          [ 50,  49,  47]],\n",
       " \n",
       "         [[196, 190, 178],\n",
       "          [188, 182, 170],\n",
       "          [181, 175, 163],\n",
       "          ...,\n",
       "          [ 51,  50,  48],\n",
       "          [ 51,  50,  48],\n",
       "          [ 50,  49,  47]]],\n",
       " \n",
       " \n",
       "        [[[110, 113, 120],\n",
       "          [110, 113, 120],\n",
       "          [111, 114, 121],\n",
       "          ...,\n",
       "          [144, 147, 130],\n",
       "          [146, 150, 135],\n",
       "          [146, 153, 137]],\n",
       " \n",
       "         [[110, 113, 120],\n",
       "          [110, 113, 120],\n",
       "          [110, 113, 120],\n",
       "          ...,\n",
       "          [143, 146, 129],\n",
       "          [146, 150, 135],\n",
       "          [146, 153, 137]],\n",
       " \n",
       "         [[109, 112, 119],\n",
       "          [109, 112, 119],\n",
       "          [109, 112, 119],\n",
       "          ...,\n",
       "          [144, 146, 132],\n",
       "          [147, 151, 137],\n",
       "          [148, 152, 138]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[149, 145, 146],\n",
       "          [152, 148, 149],\n",
       "          [151, 149, 150],\n",
       "          ...,\n",
       "          [ 86,  85,  80],\n",
       "          [ 86,  85,  80],\n",
       "          [ 86,  85,  80]],\n",
       " \n",
       "         [[149, 145, 144],\n",
       "          [152, 148, 147],\n",
       "          [153, 149, 148],\n",
       "          ...,\n",
       "          [ 83,  84,  78],\n",
       "          [ 84,  85,  79],\n",
       "          [ 84,  85,  79]],\n",
       " \n",
       "         [[149, 145, 144],\n",
       "          [153, 149, 148],\n",
       "          [153, 149, 148],\n",
       "          ...,\n",
       "          [ 83,  84,  78],\n",
       "          [ 83,  84,  78],\n",
       "          [ 83,  84,  78]]],\n",
       " \n",
       " \n",
       "        [[[ 74,  86,  64],\n",
       "          [ 75,  87,  65],\n",
       "          [ 77,  89,  67],\n",
       "          ...,\n",
       "          [101, 102,  86],\n",
       "          [100, 101,  85],\n",
       "          [ 99, 100,  84]],\n",
       " \n",
       "         [[ 74,  86,  64],\n",
       "          [ 75,  87,  65],\n",
       "          [ 77,  89,  67],\n",
       "          ...,\n",
       "          [101, 102,  86],\n",
       "          [100, 101,  85],\n",
       "          [ 99, 100,  84]],\n",
       " \n",
       "         [[ 75,  87,  65],\n",
       "          [ 76,  88,  66],\n",
       "          [ 78,  90,  68],\n",
       "          ...,\n",
       "          [102, 103,  87],\n",
       "          [101, 102,  86],\n",
       "          [100, 101,  85]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 39,  26,  17],\n",
       "          [ 49,  36,  27],\n",
       "          [ 55,  42,  34],\n",
       "          ...,\n",
       "          [108, 123,  66],\n",
       "          [113, 127,  68],\n",
       "          [120, 134,  73]],\n",
       " \n",
       "         [[ 49,  36,  27],\n",
       "          [ 56,  43,  34],\n",
       "          [ 59,  46,  38],\n",
       "          ...,\n",
       "          [102, 115,  59],\n",
       "          [101, 115,  56],\n",
       "          [ 95, 109,  48]],\n",
       " \n",
       "         [[ 56,  43,  34],\n",
       "          [ 62,  49,  40],\n",
       "          [ 62,  49,  41],\n",
       "          ...,\n",
       "          [ 99, 113,  54],\n",
       "          [ 96, 110,  51],\n",
       "          [ 85,  99,  38]]]], dtype=uint8),\n",
       " array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_rows = list(range(0,87050))\n",
    "bird_data_generator = BirdDataGenerator(csv_file=\"birds.csv\", use_rows=use_rows, batch_size=128)\n",
    "bird_data_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae55fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_cnn_model(csv_file):\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(224,224,3)),\n",
    "        Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "#         BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(511, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer = optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    print(model.summary())\n",
    "    train_rows = list(range(0,81950))\n",
    "    train_generator = BirdDataGenerator(csv_file=csv_file, use_rows=train_rows, batch_size=128)\n",
    "    h = model.fit(x=train_generator, epochs=5, verbose=1)\n",
    "    print(h)\n",
    "    \n",
    "#     validation_rows = list(range(84500, 87050))\n",
    "#     validation_generator = BirdDataGenerator(csv_file=csv_file, use_rows=validation_rows, batch_size=128)\n",
    "    \n",
    "    test_rows = list(range(81950, 84500))\n",
    "    test_generator = BirdDataGenerator(csv_file=csv_file, use_rows=test_rows, batch_size=128)\n",
    "    model.evaluate(x=test_generator)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8928421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 11:52:43.031063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-02 11:52:43.090307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-02 11:52:43.090735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-02 11:52:43.095783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-02 11:52:43.096240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-02 11:52:43.096617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-02 11:52:44.285445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-02 11:52:44.286817: I tensorflow/compile"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 394272)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 511)               201473503 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,474,399\n",
      "Trainable params: 201,474,399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-02 11:52:44.286854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-02 11:52:44.287382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-02 11:52:44.287441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3881 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "(87050, 5)\n",
      "train/ABBOTTS BABBLER/001.jpg\n",
      "(1, 224, 224, 3)\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 11:52:45.946958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-02 11:52:48.468558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-02 11:52:49.459569: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-02 11:52:49.604193: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 665.74MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-02 11:52:49.658772: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.90GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-02 11:52:49.851196: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 665.74MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-02 11:52:49.851288: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-02 11:52:49.909131: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f88ca9463e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-02 11:52:49.909192: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti with Max-Q Design, Compute Capability 7.5\n",
      "2023-04-02 11:52:50.101180: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-02 11:52:50.159460: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/640 [..............................] - ETA: 52:04 - loss: 158.6733 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 11:52:50.675514: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.90GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-02 11:52:50.736774: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-02 11:52:50.736860: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 646s 1s/step - loss: 595.7845 - accuracy: 0.0010\n",
      "Epoch 2/5\n",
      "640/640 [==============================] - 658s 1s/step - loss: 6.2274 - accuracy: 0.0031\n",
      "Epoch 3/5\n",
      "640/640 [==============================] - 641s 1s/step - loss: 6.1996 - accuracy: 0.0056\n",
      "Epoch 4/5\n",
      "640/640 [==============================] - 648s 1s/step - loss: 6.1069 - accuracy: 0.0143\n",
      "Epoch 5/5\n",
      "640/640 [==============================] - 645s 1s/step - loss: 5.9571 - accuracy: 0.0258\n",
      "<keras.callbacks.History object at 0x7f8b42b6c190>\n",
      "(87050, 5)\n",
      "train/ABBOTTS BABBLER/001.jpg\n",
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 12:46:45.666953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 21s 1s/step - loss: 6.1987 - accuracy: 0.0095\n"
     ]
    }
   ],
   "source": [
    "cnn_model = bird_cnn_model(\"birds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed1d1429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "2023-04-02 12:47:58.208271: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 805891968 exceeds 10% of free system memory.\n",
      "2023-04-02 12:47:58.975807: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 805891968 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: base_5_epochs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: base_5_epochs/assets\n"
     ]
    }
   ],
   "source": [
    "cnn_model.save(\"base_5_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02307493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
