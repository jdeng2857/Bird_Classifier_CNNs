{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5392d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 06:26:32.515235: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 06:26:33.587061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a67bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, use_rows, batch_size, csv_file=\"birds.csv\"):\n",
    "        self.csv_df = pd.read_csv(csv_file)\n",
    "        self.use_rows = use_rows\n",
    "        self.batch_size = batch_size \n",
    "        self.dataset = pd.DataFrame(self.csv_df).to_numpy()\n",
    "    \n",
    "        self.labels = self.dataset[:,2]\n",
    "        self.img_filepaths = self.dataset[:,1]\n",
    "        self.class_ids = self.dataset[:,0]\n",
    "        \n",
    "        (x,) = self.img_filepaths.shape\n",
    "        print(self.dataset.shape)\n",
    "        print(self.img_filepaths[0])\n",
    "        image = Image.open(self.img_filepaths[0])\n",
    "        image_array = np.expand_dims(np.asarray(image), axis=0)\n",
    "        \n",
    "#         print(image_array)\n",
    "        print(image_array.shape)\n",
    "        \n",
    "#         self.images = []\n",
    "        \n",
    "#         for i in range(0, 10):\n",
    "#             image = Image.open(self.img_filepaths[0])\n",
    "#             image_array = np.expand_dims(np.asarray(image), axis=0)\n",
    "#             self.images.append(image_array)\n",
    "            \n",
    "#         self.images = np.array(self.images)\n",
    "        \n",
    "#         print(self.images.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # batches_per_epoch is the total number of batches used for one epoch\n",
    "        batches_per_epoch = int(len(self.use_rows) / self.batch_size)\n",
    "        return batches_per_epoch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # index is the index of the batch to be retrieved\n",
    "        batch_ids = self.use_rows[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        \n",
    "        x = None\n",
    "        y = None\n",
    "        \n",
    "        images = []\n",
    "        id_labels = []\n",
    "        \n",
    "        for curr_id in batch_ids:\n",
    "            image = Image.open(self.img_filepaths[curr_id])\n",
    "            image_array = np.expand_dims(np.asarray(image),axis=0)\n",
    "            \n",
    "            if x is None:\n",
    "                x = image_array\n",
    "                y = self.class_ids[curr_id] -1 \n",
    "            else:\n",
    "                x = np.vstack((x, image_array))\n",
    "                y = np.vstack((y, self.class_ids[curr_id] -1))\n",
    "                \n",
    "    \n",
    "#             print(self.class_ids[curr_id-1])\n",
    "            \n",
    "        \n",
    "#         images = np.array(images)\n",
    "#         id_labels = np.array(id_labels)\n",
    "#         print(id_labels)\n",
    "#         print(images.shape)\n",
    "#         print(id_labels.shape)\n",
    "#         print(self.class_ids)\n",
    "        \n",
    "#         print(self.class_ids.shape)\n",
    "        \n",
    "        \n",
    "        y = tf.keras.utils.to_categorical(y, num_classes=511)\n",
    "#         print(x.shape)\n",
    "#         print(y.shape)\n",
    "        return x, y            \n",
    "            \n",
    "#     def on_epoch_end(self):\n",
    "#         np.random.shuffle(self.split_ids)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b43122b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87050, 5)\n",
      "train/ABBOTTS BABBLER/001.jpg\n",
      "(1, 224, 224, 3)\n",
      "510.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "(128, 224, 224, 3)\n",
      "(128, 511)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[180, 172, 149],\n",
       "          [186, 178, 155],\n",
       "          [186, 180, 158],\n",
       "          ...,\n",
       "          [181, 180, 198],\n",
       "          [179, 180, 200],\n",
       "          [178, 179, 199]],\n",
       " \n",
       "         [[182, 174, 153],\n",
       "          [190, 182, 161],\n",
       "          [190, 184, 162],\n",
       "          ...,\n",
       "          [182, 181, 199],\n",
       "          [176, 177, 197],\n",
       "          [178, 179, 199]],\n",
       " \n",
       "         [[186, 178, 159],\n",
       "          [195, 187, 168],\n",
       "          [196, 189, 170],\n",
       "          ...,\n",
       "          [184, 183, 199],\n",
       "          [180, 179, 197],\n",
       "          [183, 182, 200]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[151, 138, 121],\n",
       "          [172, 159, 142],\n",
       "          [178, 165, 146],\n",
       "          ...,\n",
       "          [189, 190, 211],\n",
       "          [191, 189, 210],\n",
       "          [169, 167, 188]],\n",
       " \n",
       "         [[156, 140, 124],\n",
       "          [155, 139, 123],\n",
       "          [161, 148, 131],\n",
       "          ...,\n",
       "          [186, 188, 211],\n",
       "          [182, 185, 204],\n",
       "          [168, 171, 188]],\n",
       " \n",
       "         [[157, 141, 125],\n",
       "          [156, 140, 124],\n",
       "          [167, 154, 137],\n",
       "          ...,\n",
       "          [169, 174, 196],\n",
       "          [181, 186, 205],\n",
       "          [147, 153, 169]]],\n",
       " \n",
       " \n",
       "        [[[ 37,  62,  33],\n",
       "          [ 39,  64,  35],\n",
       "          [ 39,  62,  34],\n",
       "          ...,\n",
       "          [ 51,  82,  50],\n",
       "          [ 52,  82,  48],\n",
       "          [ 54,  84,  50]],\n",
       " \n",
       "         [[ 37,  62,  33],\n",
       "          [ 39,  64,  35],\n",
       "          [ 39,  62,  34],\n",
       "          ...,\n",
       "          [ 53,  84,  52],\n",
       "          [ 53,  83,  49],\n",
       "          [ 53,  83,  49]],\n",
       " \n",
       "         [[ 38,  63,  34],\n",
       "          [ 39,  64,  35],\n",
       "          [ 38,  63,  34],\n",
       "          ...,\n",
       "          [ 55,  86,  54],\n",
       "          [ 54,  84,  50],\n",
       "          [ 53,  83,  49]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[154, 128, 111],\n",
       "          [123,  96,  79],\n",
       "          [ 87,  55,  44],\n",
       "          ...,\n",
       "          [ 60,  87,  78],\n",
       "          [ 58,  85,  76],\n",
       "          [ 56,  83,  74]],\n",
       " \n",
       "         [[108,  76,  63],\n",
       "          [ 85,  52,  43],\n",
       "          [111,  77,  75],\n",
       "          ...,\n",
       "          [ 60,  87,  78],\n",
       "          [ 59,  85,  76],\n",
       "          [ 57,  83,  74]],\n",
       " \n",
       "         [[122,  88,  78],\n",
       "          [160, 125, 119],\n",
       "          [187, 153, 154],\n",
       "          ...,\n",
       "          [ 60,  87,  78],\n",
       "          [ 60,  86,  77],\n",
       "          [ 58,  84,  75]]],\n",
       " \n",
       " \n",
       "        [[[238, 238, 230],\n",
       "          [237, 237, 229],\n",
       "          [238, 238, 228],\n",
       "          ...,\n",
       "          [ 89,  77,  65],\n",
       "          [ 83,  71,  57],\n",
       "          [ 80,  68,  52]],\n",
       " \n",
       "         [[238, 238, 230],\n",
       "          [237, 237, 229],\n",
       "          [238, 238, 228],\n",
       "          ...,\n",
       "          [ 81,  69,  57],\n",
       "          [ 83,  71,  57],\n",
       "          [ 86,  74,  60]],\n",
       " \n",
       "         [[237, 237, 227],\n",
       "          [236, 236, 226],\n",
       "          [237, 237, 227],\n",
       "          ...,\n",
       "          [ 82,  70,  56],\n",
       "          [ 87,  75,  63],\n",
       "          [ 83,  71,  59]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 99, 138,  29],\n",
       "          [111, 148,  42],\n",
       "          [114, 149,  47],\n",
       "          ...,\n",
       "          [ 39,  39,  37],\n",
       "          [ 44,  44,  44],\n",
       "          [ 44,  44,  44]],\n",
       " \n",
       "         [[106, 145,  38],\n",
       "          [122, 159,  54],\n",
       "          [108, 143,  43],\n",
       "          ...,\n",
       "          [ 41,  43,  40],\n",
       "          [ 46,  46,  46],\n",
       "          [ 44,  44,  44]],\n",
       " \n",
       "         [[107, 146,  39],\n",
       "          [112, 149,  44],\n",
       "          [118, 152,  55],\n",
       "          ...,\n",
       "          [ 41,  43,  38],\n",
       "          [ 46,  46,  46],\n",
       "          [ 42,  42,  42]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          ...,\n",
       "          [ 71,  62,  55],\n",
       "          [ 70,  61,  54],\n",
       "          [ 70,  61,  54]],\n",
       " \n",
       "         [[ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          ...,\n",
       "          [ 70,  61,  54],\n",
       "          [ 70,  61,  54],\n",
       "          [ 70,  61,  54]],\n",
       " \n",
       "         [[ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          [ 83,  74,  69],\n",
       "          ...,\n",
       "          [ 70,  61,  54],\n",
       "          [ 69,  60,  53],\n",
       "          [ 69,  60,  53]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 97,  91,  79],\n",
       "          [ 98,  92,  80],\n",
       "          [106, 100,  88],\n",
       "          ...,\n",
       "          [ 49,  48,  46],\n",
       "          [ 49,  48,  46],\n",
       "          [ 49,  48,  46]],\n",
       " \n",
       "         [[152, 146, 134],\n",
       "          [149, 143, 131],\n",
       "          [150, 144, 132],\n",
       "          ...,\n",
       "          [ 50,  49,  47],\n",
       "          [ 50,  49,  47],\n",
       "          [ 50,  49,  47]],\n",
       " \n",
       "         [[196, 190, 178],\n",
       "          [188, 182, 170],\n",
       "          [181, 175, 163],\n",
       "          ...,\n",
       "          [ 51,  50,  48],\n",
       "          [ 51,  50,  48],\n",
       "          [ 50,  49,  47]]],\n",
       " \n",
       " \n",
       "        [[[110, 113, 120],\n",
       "          [110, 113, 120],\n",
       "          [111, 114, 121],\n",
       "          ...,\n",
       "          [144, 147, 130],\n",
       "          [146, 150, 135],\n",
       "          [146, 153, 137]],\n",
       " \n",
       "         [[110, 113, 120],\n",
       "          [110, 113, 120],\n",
       "          [110, 113, 120],\n",
       "          ...,\n",
       "          [143, 146, 129],\n",
       "          [146, 150, 135],\n",
       "          [146, 153, 137]],\n",
       " \n",
       "         [[109, 112, 119],\n",
       "          [109, 112, 119],\n",
       "          [109, 112, 119],\n",
       "          ...,\n",
       "          [144, 146, 132],\n",
       "          [147, 151, 137],\n",
       "          [148, 152, 138]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[149, 145, 146],\n",
       "          [152, 148, 149],\n",
       "          [151, 149, 150],\n",
       "          ...,\n",
       "          [ 86,  85,  80],\n",
       "          [ 86,  85,  80],\n",
       "          [ 86,  85,  80]],\n",
       " \n",
       "         [[149, 145, 144],\n",
       "          [152, 148, 147],\n",
       "          [153, 149, 148],\n",
       "          ...,\n",
       "          [ 83,  84,  78],\n",
       "          [ 84,  85,  79],\n",
       "          [ 84,  85,  79]],\n",
       " \n",
       "         [[149, 145, 144],\n",
       "          [153, 149, 148],\n",
       "          [153, 149, 148],\n",
       "          ...,\n",
       "          [ 83,  84,  78],\n",
       "          [ 83,  84,  78],\n",
       "          [ 83,  84,  78]]],\n",
       " \n",
       " \n",
       "        [[[ 74,  86,  64],\n",
       "          [ 75,  87,  65],\n",
       "          [ 77,  89,  67],\n",
       "          ...,\n",
       "          [101, 102,  86],\n",
       "          [100, 101,  85],\n",
       "          [ 99, 100,  84]],\n",
       " \n",
       "         [[ 74,  86,  64],\n",
       "          [ 75,  87,  65],\n",
       "          [ 77,  89,  67],\n",
       "          ...,\n",
       "          [101, 102,  86],\n",
       "          [100, 101,  85],\n",
       "          [ 99, 100,  84]],\n",
       " \n",
       "         [[ 75,  87,  65],\n",
       "          [ 76,  88,  66],\n",
       "          [ 78,  90,  68],\n",
       "          ...,\n",
       "          [102, 103,  87],\n",
       "          [101, 102,  86],\n",
       "          [100, 101,  85]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 39,  26,  17],\n",
       "          [ 49,  36,  27],\n",
       "          [ 55,  42,  34],\n",
       "          ...,\n",
       "          [108, 123,  66],\n",
       "          [113, 127,  68],\n",
       "          [120, 134,  73]],\n",
       " \n",
       "         [[ 49,  36,  27],\n",
       "          [ 56,  43,  34],\n",
       "          [ 59,  46,  38],\n",
       "          ...,\n",
       "          [102, 115,  59],\n",
       "          [101, 115,  56],\n",
       "          [ 95, 109,  48]],\n",
       " \n",
       "         [[ 56,  43,  34],\n",
       "          [ 62,  49,  40],\n",
       "          [ 62,  49,  41],\n",
       "          ...,\n",
       "          [ 99, 113,  54],\n",
       "          [ 96, 110,  51],\n",
       "          [ 85,  99,  38]]]], dtype=uint8),\n",
       " array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_rows = list(range(0,87050))\n",
    "bird_data_generator = BirdDataGenerator(csv_file=\"birds.csv\", use_rows=use_rows, batch_size=128)\n",
    "bird_data_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ae55fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_cnn_model(csv_file):\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(224,224,3)),\n",
    "        Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "#         BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(511, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer = optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    print(model.summary())\n",
    "    train_rows = list(range(0,81950))\n",
    "    train_generator = BirdDataGenerator(csv_file=csv_file, use_rows=train_rows, batch_size=128)\n",
    "    h = model.fit(x=train_generator, epochs=1, verbose=1)\n",
    "    print(h)\n",
    "    \n",
    "#     validation_rows = list(range(84500, 87050))\n",
    "#     validation_generator = BirdDataGenerator(csv_file=csv_file, use_rows=validation_rows, batch_size=128)\n",
    "    \n",
    "#     test_rows = list(range(81950, 84500))\n",
    "#     test_generator = BirdDataGenerator(csv_file=csv_file, use_rows=test_rows, batch_size=128)\n",
    "#     model.evaluate(x=test_generator)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8928421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 394272)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 511)               201473503 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,474,399\n",
      "Trainable params: 201,474,399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(87050, 5)\n",
      "train/ABBOTTS BABBLER/001.jpg\n",
      "(1, 224, 224, 3)\n",
      "510.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "(128, 224, 224, 3)\n",
      "(128, 511)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 06:30:43.301472: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "283.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "284.0\n",
      "(128, 224, 224, 3)\n",
      "(128, 511)\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "208.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "209.0\n",
      "(128, 224, 224, 3)\n",
      "(128, 511)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 06:30:55.253460: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 770.06MiB (rounded to 807469056)requested by op sequential_1/conv2d_1/Relu\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-03-31 06:30:55.253582: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-03-31 06:30:55.253599: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 484B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253606: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253615: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.2KiB allocated for chunks. 2.2KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253621: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 5, Chunks in use: 5. 14.5KiB allocated for chunks. 14.5KiB in use in bin. 12.7KiB client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253626: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 6.2KiB allocated for chunks. 6.2KiB in use in bin. 3.4KiB client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253630: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253635: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253639: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253644: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253649: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 255.5KiB allocated for chunks. 255.5KiB in use in bin. 255.5KiB client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253654: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253658: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253663: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253668: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253672: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253676: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253681: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 0. 36.75MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253686: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253691: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 73.50MiB allocated for chunks. 73.50MiB in use in bin. 73.50MiB client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253696: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253701: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 5, Chunks in use: 3. 3.68GiB allocated for chunks. 2.29GiB in use in bin. 2.25GiB client-requested in use in bin.\n",
      "2023-03-31 06:30:55.253708: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 770.06MiB was 256.00MiB, Chunk State: \n",
      "2023-03-31 06:30:55.253721: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 658.04MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 73.50MiB | Requested Size: 73.50MiB | in_use: 1 | bin_num: -1, next:   Size: 768.56MiB | Requested Size: 768.56MiB | in_use: 1 | bin_num: -1\n",
      "2023-03-31 06:30:55.253728: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 768.56MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 256B | Requested Size: 128B | in_use: 1 | bin_num: -1, next:   Size: 806.75MiB | Requested Size: 768.56MiB | in_use: 1 | bin_num: -1\n",
      "2023-03-31 06:30:55.253732: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 4069523456\n",
      "2023-03-31 06:30:55.253739: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811400000 of size 256 next 1\n",
      "2023-03-31 06:30:55.253743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811400100 of size 1280 next 2\n",
      "2023-03-31 06:30:55.253747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811400600 of size 256 next 3\n",
      "2023-03-31 06:30:55.253750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811400700 of size 256 next 4\n",
      "2023-03-31 06:30:55.253754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811400800 of size 256 next 6\n",
      "2023-03-31 06:30:55.253757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811400900 of size 256 next 7\n",
      "2023-03-31 06:30:55.253761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811400a00 of size 256 next 5\n",
      "2023-03-31 06:30:55.253764: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811400b00 of size 256 next 8\n",
      "2023-03-31 06:30:55.253768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811400c00 of size 2048 next 13\n",
      "2023-03-31 06:30:55.253771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811401400 of size 256 next 11\n",
      "2023-03-31 06:30:55.253775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811401500 of size 256 next 12\n",
      "2023-03-31 06:30:55.253779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811401600 of size 256 next 16\n",
      "2023-03-31 06:30:55.253782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811401700 of size 256 next 17\n",
      "2023-03-31 06:30:55.253786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811401800 of size 256 next 20\n",
      "2023-03-31 06:30:55.253789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811401900 of size 3584 next 9\n",
      "2023-03-31 06:30:55.253793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811402700 of size 3584 next 10\n",
      "2023-03-31 06:30:55.253797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811403500 of size 256 next 23\n",
      "2023-03-31 06:30:55.253800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811403600 of size 256 next 18\n",
      "2023-03-31 06:30:55.253804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811403700 of size 256 next 19\n",
      "2023-03-31 06:30:55.253807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811403800 of size 6400 next 22\n",
      "2023-03-31 06:30:55.253811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811405100 of size 3584 next 21\n",
      "2023-03-31 06:30:55.253815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 811405f00 of size 805892096 next 26\n",
      "2023-03-31 06:30:55.253818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 841494f00 of size 2048 next 27\n",
      "2023-03-31 06:30:55.253822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 841495700 of size 256 next 28\n",
      "2023-03-31 06:30:55.253825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 841495800 of size 256 next 29\n",
      "2023-03-31 06:30:55.253828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 841495900 of size 256 next 30\n",
      "2023-03-31 06:30:55.253832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 841495a00 of size 256 next 31\n",
      "2023-03-31 06:30:55.253836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 841495b00 of size 256 next 32\n",
      "2023-03-31 06:30:55.253839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 841495c00 of size 256 next 33\n",
      "2023-03-31 06:30:55.253844: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 841495d00 of size 261632 next 34\n",
      "2023-03-31 06:30:55.253848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 8414d5b00 of size 256 next 39\n",
      "2023-03-31 06:30:55.253851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 8414d5c00 of size 19267584 next 36\n",
      "2023-03-31 06:30:55.253855: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 842735c00 of size 1024 next 37\n",
      "2023-03-31 06:30:55.253859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 842736000 of size 19267584 next 38\n",
      "2023-03-31 06:30:55.253862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 843996000 of size 77070336 next 40\n",
      "2023-03-31 06:30:55.253866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 848316000 of size 690009344 next 15\n",
      "2023-03-31 06:30:55.253870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 871521500 of size 805892096 next 14\n",
      "2023-03-31 06:30:55.253873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 8a15b0500 of size 256 next 24\n",
      "2023-03-31 06:30:55.253877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 8a15b0600 of size 805891840 next 25\n",
      "2023-03-31 06:30:55.253880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 8d163f500 of size 845941504 next 18446744073709551615\n",
      "2023-03-31 06:30:55.253884: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-03-31 06:30:55.253890: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 23 Chunks of size 256 totalling 5.8KiB\n",
      "2023-03-31 06:30:55.253894: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1024 totalling 1.0KiB\n",
      "2023-03-31 06:30:55.253898: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-03-31 06:30:55.253902: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 2048 totalling 4.0KiB\n",
      "2023-03-31 06:30:55.253906: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 3584 totalling 10.5KiB\n",
      "2023-03-31 06:30:55.253910: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6400 totalling 6.2KiB\n",
      "2023-03-31 06:30:55.253914: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 261632 totalling 255.5KiB\n",
      "2023-03-31 06:30:55.253919: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 77070336 totalling 73.50MiB\n",
      "2023-03-31 06:30:55.253923: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 805892096 totalling 1.50GiB\n",
      "2023-03-31 06:30:55.253928: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 845941504 totalling 806.75MiB\n",
      "2023-03-31 06:30:55.253932: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 2.36GiB\n",
      "2023-03-31 06:30:55.253936: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 4069523456 memory_limit_: 4069523456 available bytes: 0 curr_region_allocation_bytes_: 8139046912\n",
      "2023-03-31 06:30:55.253944: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      4069523456\n",
      "InUse:                      2535087104\n",
      "MaxInUse:                   3263631872\n",
      "NumAllocs:                          63\n",
      "MaxAllocSize:                845941504\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-03-31 06:30:55.253951: W tensorflow/tsl/framework/bfc_allocator.cc:497] ***********************________________*********************___________________*********************\n",
      "2023-03-31 06:30:55.254015: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops_fused_impl.h:772 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128,32,222,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2023-03-31 06:30:55.254065: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128,32,222,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node sequential_1/conv2d_1/Relu}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/conv2d_1/Relu' defined at (most recent call last):\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_18219/1529991850.py\", line 1, in <module>\n      cnn_model = bird_cnn_model(\"birds.csv\")\n    File \"/tmp/ipykernel_18219/2674139323.py\", line 17, in bird_cnn_model\n      h = model.fit(x=train_generator, epochs=1, verbose=1)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_1/conv2d_1/Relu'\nOOM when allocating tensor with shape[128,32,222,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_1/conv2d_1/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_808]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mbird_cnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbirds.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m, in \u001b[0;36mbird_cnn_model\u001b[0;34m(csv_file)\u001b[0m\n\u001b[1;32m     15\u001b[0m train_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m81950\u001b[39m))\n\u001b[1;32m     16\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m BirdDataGenerator(csv_file\u001b[38;5;241m=\u001b[39mcsv_file, use_rows\u001b[38;5;241m=\u001b[39mtrain_rows, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(h)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_1/conv2d_1/Relu' defined at (most recent call last):\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_18219/1529991850.py\", line 1, in <module>\n      cnn_model = bird_cnn_model(\"birds.csv\")\n    File \"/tmp/ipykernel_18219/2674139323.py\", line 17, in bird_cnn_model\n      h = model.fit(x=train_generator, epochs=1, verbose=1)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_1/conv2d_1/Relu'\nOOM when allocating tensor with shape[128,32,222,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_1/conv2d_1/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_808]"
     ]
    }
   ],
   "source": [
    "cnn_model = bird_cnn_model(\"birds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d1429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
