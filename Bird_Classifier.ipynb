{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5392d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 19:54:56.771729: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-30 19:54:57.979041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a67bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, use_rows, batch_size, csv_file=\"birds.csv\"):\n",
    "        self.csv_df = pd.read_csv(csv_file)\n",
    "        self.use_rows = use_rows\n",
    "        self.batch_size = batch_size \n",
    "        self.dataset = pd.DataFrame(self.csv_df).to_numpy()\n",
    "    \n",
    "        self.labels = self.dataset[:,2]\n",
    "        self.img_filepaths = self.dataset[:,1]\n",
    "        self.class_ids = self.dataset[:,0]\n",
    "        \n",
    "        (x,) = self.img_filepaths.shape\n",
    "        print(self.dataset.shape)\n",
    "        print(self.img_filepaths[0])\n",
    "        image = Image.open(self.img_filepaths[0])\n",
    "        image_array = np.expand_dims(np.asarray(image), axis=0)\n",
    "        \n",
    "#         print(image_array)\n",
    "        print(image_array.shape)\n",
    "        \n",
    "#         self.images = []\n",
    "        \n",
    "#         for i in range(0, 10):\n",
    "#             image = Image.open(self.img_filepaths[0])\n",
    "#             image_array = np.expand_dims(np.asarray(image), axis=0)\n",
    "#             self.images.append(image_array)\n",
    "            \n",
    "#         self.images = np.array(self.images)\n",
    "        \n",
    "#         print(self.images.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # batches_per_epoch is the total number of batches used for one epoch\n",
    "        batches_per_epoch = int(len(self.use_rows) / self.batch_size)\n",
    "        return batches_per_epoch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # index is the index of the batch to be retrieved\n",
    "        batch_ids = self.use_rows[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        \n",
    "        x = None\n",
    "        y = None\n",
    "        \n",
    "        images = []\n",
    "        id_labels = []\n",
    "        \n",
    "        for curr_id in batch_ids:\n",
    "            image = Image.open(self.img_filepaths[curr_id])\n",
    "            img_array = np.asarray(image)\n",
    "            images.append(img_array)\n",
    "            id_labels.append(self.class_ids[curr_id])\n",
    "#             print(self.class_ids[curr_id-1])\n",
    "            \n",
    "        \n",
    "        images = np.array(images)\n",
    "        id_labels = np.array(id_labels)\n",
    "#         print(id_labels)\n",
    "#         print(images.shape)\n",
    "#         print(id_labels.shape)\n",
    "#         print(self.class_ids)\n",
    "        \n",
    "#         print(self.class_ids.shape)\n",
    "        \n",
    "        x = images\n",
    "        y = id_labels\n",
    "        \n",
    "        y = tf.keras.utils.to_categorical(y, num_classes=510)\n",
    "#         print(x.shape)\n",
    "#         print(y.shape)\n",
    "        return x, y            \n",
    "            \n",
    "#     def on_epoch_end(self):\n",
    "#         np.random.shuffle(self.split_ids)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43122b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87050, 5)\n",
      "train/ABBOTTS BABBLER/001.jpg\n",
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[ 80, 163, 167],\n",
       "          [ 79, 162, 166],\n",
       "          [ 82, 163, 167],\n",
       "          ...,\n",
       "          [ 38,  73,  75],\n",
       "          [ 39,  73,  74],\n",
       "          [ 39,  73,  74]],\n",
       " \n",
       "         [[ 83, 164, 168],\n",
       "          [ 83, 164, 168],\n",
       "          [ 84, 165, 169],\n",
       "          ...,\n",
       "          [ 39,  74,  76],\n",
       "          [ 40,  74,  75],\n",
       "          [ 40,  74,  75]],\n",
       " \n",
       "         [[ 84, 163, 168],\n",
       "          [ 85, 164, 169],\n",
       "          [ 87, 166, 171],\n",
       "          ...,\n",
       "          [ 37,  75,  76],\n",
       "          [ 40,  76,  76],\n",
       "          [ 41,  77,  77]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 48, 123, 126],\n",
       "          [ 47, 122, 125],\n",
       "          [ 50, 121, 125],\n",
       "          ...,\n",
       "          [ 61, 125, 125],\n",
       "          [ 61, 125, 125],\n",
       "          [ 60, 124, 124]],\n",
       " \n",
       "         [[ 47, 122, 125],\n",
       "          [ 47, 122, 125],\n",
       "          [ 51, 122, 126],\n",
       "          ...,\n",
       "          [ 61, 125, 125],\n",
       "          [ 63, 124, 125],\n",
       "          [ 64, 125, 126]],\n",
       " \n",
       "         [[ 47, 122, 125],\n",
       "          [ 47, 122, 125],\n",
       "          [ 53, 124, 128],\n",
       "          ...,\n",
       "          [ 60, 124, 124],\n",
       "          [ 61, 122, 123],\n",
       "          [ 65, 126, 127]]],\n",
       " \n",
       " \n",
       "        [[[118, 144,  45],\n",
       "          [120, 146,  47],\n",
       "          [123, 148,  54],\n",
       "          ...,\n",
       "          [127, 143,  72],\n",
       "          [114, 129,  64],\n",
       "          [ 94, 110,  48]],\n",
       " \n",
       "         [[112, 139,  42],\n",
       "          [113, 140,  43],\n",
       "          [115, 142,  47],\n",
       "          ...,\n",
       "          [115, 130,  61],\n",
       "          [100, 116,  54],\n",
       "          [ 76,  91,  34]],\n",
       " \n",
       "         [[105, 135,  39],\n",
       "          [106, 135,  42],\n",
       "          [107, 136,  43],\n",
       "          ...,\n",
       "          [108, 122,  61],\n",
       "          [ 90, 104,  51],\n",
       "          [ 64,  78,  27]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 85, 140,  73],\n",
       "          [ 84, 139,  72],\n",
       "          [ 88, 143,  76],\n",
       "          ...,\n",
       "          [164, 201, 157],\n",
       "          [153, 188, 148],\n",
       "          [166, 200, 163]],\n",
       " \n",
       "         [[ 82, 139,  70],\n",
       "          [ 81, 138,  69],\n",
       "          [ 87, 144,  76],\n",
       "          ...,\n",
       "          [158, 196, 145],\n",
       "          [164, 200, 156],\n",
       "          [148, 183, 141]],\n",
       " \n",
       "         [[ 83, 140,  69],\n",
       "          [ 82, 139,  68],\n",
       "          [ 86, 143,  75],\n",
       "          ...,\n",
       "          [147, 186, 133],\n",
       "          [148, 184, 138],\n",
       "          [161, 197, 153]]],\n",
       " \n",
       " \n",
       "        [[[ 19,  35,   0],\n",
       "          [ 26,  43,   1],\n",
       "          [ 33,  45,   5],\n",
       "          ...,\n",
       "          [163, 193, 129],\n",
       "          [163, 193, 129],\n",
       "          [163, 193, 129]],\n",
       " \n",
       "         [[ 21,  36,   0],\n",
       "          [ 28,  43,   4],\n",
       "          [ 34,  46,   6],\n",
       "          ...,\n",
       "          [165, 195, 133],\n",
       "          [166, 196, 134],\n",
       "          [167, 197, 135]],\n",
       " \n",
       "         [[ 24,  36,   0],\n",
       "          [ 31,  43,   5],\n",
       "          [ 35,  47,   7],\n",
       "          ...,\n",
       "          [167, 198, 139],\n",
       "          [168, 199, 140],\n",
       "          [169, 200, 141]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 40,  40,  30],\n",
       "          [ 43,  43,  33],\n",
       "          [ 45,  45,  35],\n",
       "          ...,\n",
       "          [ 91, 122,  55],\n",
       "          [ 94, 123,  56],\n",
       "          [ 94, 124,  54]],\n",
       " \n",
       "         [[ 56,  53,  46],\n",
       "          [ 59,  56,  49],\n",
       "          [ 60,  60,  52],\n",
       "          ...,\n",
       "          [ 82, 111,  45],\n",
       "          [ 82, 111,  44],\n",
       "          [ 84, 113,  46]],\n",
       " \n",
       "         [[ 64,  61,  54],\n",
       "          [ 69,  66,  59],\n",
       "          [ 70,  69,  64],\n",
       "          ...,\n",
       "          [ 87, 116,  50],\n",
       "          [ 87, 116,  50],\n",
       "          [ 90, 119,  52]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[116, 115,  94],\n",
       "          [116, 115,  94],\n",
       "          [116, 115,  94],\n",
       "          ...,\n",
       "          [124, 128,  93],\n",
       "          [124, 128,  93],\n",
       "          [124, 128,  93]],\n",
       " \n",
       "         [[116, 115,  94],\n",
       "          [116, 115,  94],\n",
       "          [116, 115,  94],\n",
       "          ...,\n",
       "          [124, 128,  93],\n",
       "          [124, 128,  93],\n",
       "          [124, 128,  93]],\n",
       " \n",
       "         [[115, 117,  95],\n",
       "          [115, 117,  95],\n",
       "          [115, 117,  95],\n",
       "          ...,\n",
       "          [126, 127,  93],\n",
       "          [126, 127,  93],\n",
       "          [126, 127,  93]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[115, 125,  75],\n",
       "          [115, 125,  75],\n",
       "          [116, 125,  78],\n",
       "          ...,\n",
       "          [122, 129,  87],\n",
       "          [122, 129,  87],\n",
       "          [122, 129,  87]],\n",
       " \n",
       "         [[115, 123,  76],\n",
       "          [116, 124,  77],\n",
       "          [117, 126,  81],\n",
       "          ...,\n",
       "          [122, 127,  86],\n",
       "          [122, 127,  86],\n",
       "          [122, 127,  86]],\n",
       " \n",
       "         [[123, 130,  86],\n",
       "          [121, 128,  84],\n",
       "          [117, 126,  83],\n",
       "          ...,\n",
       "          [121, 126,  85],\n",
       "          [121, 126,  85],\n",
       "          [121, 126,  85]]],\n",
       " \n",
       " \n",
       "        [[[ 64,  76,  56],\n",
       "          [ 64,  76,  56],\n",
       "          [ 64,  76,  56],\n",
       "          ...,\n",
       "          [ 54,  72,  32],\n",
       "          [ 54,  72,  32],\n",
       "          [ 54,  72,  32]],\n",
       " \n",
       "         [[ 65,  77,  57],\n",
       "          [ 65,  77,  57],\n",
       "          [ 65,  77,  57],\n",
       "          ...,\n",
       "          [ 54,  72,  32],\n",
       "          [ 54,  72,  32],\n",
       "          [ 54,  72,  32]],\n",
       " \n",
       "         [[ 67,  78,  61],\n",
       "          [ 67,  78,  61],\n",
       "          [ 67,  78,  61],\n",
       "          ...,\n",
       "          [ 54,  72,  32],\n",
       "          [ 54,  72,  32],\n",
       "          [ 54,  72,  32]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 58,  67,  24],\n",
       "          [ 58,  67,  24],\n",
       "          [ 58,  67,  24],\n",
       "          ...,\n",
       "          [ 40,  52,  28],\n",
       "          [ 40,  52,  28],\n",
       "          [ 40,  52,  28]],\n",
       " \n",
       "         [[ 58,  67,  22],\n",
       "          [ 58,  67,  22],\n",
       "          [ 59,  66,  22],\n",
       "          ...,\n",
       "          [ 40,  52,  28],\n",
       "          [ 40,  52,  28],\n",
       "          [ 40,  52,  28]],\n",
       " \n",
       "         [[ 58,  67,  22],\n",
       "          [ 58,  67,  22],\n",
       "          [ 59,  66,  22],\n",
       "          ...,\n",
       "          [ 40,  52,  28],\n",
       "          [ 40,  52,  28],\n",
       "          [ 40,  52,  28]]],\n",
       " \n",
       " \n",
       "        [[[202, 161, 143],\n",
       "          [202, 161, 143],\n",
       "          [202, 161, 143],\n",
       "          ...,\n",
       "          [ 77,  64,  48],\n",
       "          [ 76,  63,  47],\n",
       "          [ 76,  63,  47]],\n",
       " \n",
       "         [[205, 164, 146],\n",
       "          [205, 164, 146],\n",
       "          [204, 163, 145],\n",
       "          ...,\n",
       "          [ 76,  63,  47],\n",
       "          [ 76,  63,  47],\n",
       "          [ 76,  63,  47]],\n",
       " \n",
       "         [[207, 166, 148],\n",
       "          [207, 166, 148],\n",
       "          [206, 165, 147],\n",
       "          ...,\n",
       "          [ 76,  63,  47],\n",
       "          [ 74,  62,  46],\n",
       "          [ 74,  62,  46]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 36,  36,  24],\n",
       "          [ 42,  42,  30],\n",
       "          [ 45,  45,  33],\n",
       "          ...,\n",
       "          [ 42,  44,  33],\n",
       "          [ 37,  40,  29],\n",
       "          [ 30,  33,  22]],\n",
       " \n",
       "         [[ 37,  39,  25],\n",
       "          [ 43,  45,  31],\n",
       "          [ 48,  49,  35],\n",
       "          ...,\n",
       "          [ 43,  45,  34],\n",
       "          [ 39,  42,  31],\n",
       "          [ 34,  37,  26]],\n",
       " \n",
       "         [[ 35,  39,  22],\n",
       "          [ 40,  44,  27],\n",
       "          [ 48,  49,  33],\n",
       "          ...,\n",
       "          [ 43,  45,  34],\n",
       "          [ 39,  42,  31],\n",
       "          [ 34,  37,  26]]]], dtype=uint8),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_rows = list(range(0,87050))\n",
    "bird_data_generator = BirdDataGenerator(csv_file=\"birds.csv\", use_rows=use_rows, batch_size=32)\n",
    "bird_data_generator.__getitem__(2700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae55fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_cnn_model(csv_file):\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(224,224,3)),\n",
    "        Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "#         BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(510, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer = optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    print(model.summary())\n",
    "    train_rows = list(range(0,81950))\n",
    "    train_generator = BirdDataGenerator(csv_file=csv_file, use_rows=train_rows, batch_size=128)\n",
    "    h = model.fit(x=train_generator, epochs=4, verbose=1)\n",
    "    print(h)\n",
    "    \n",
    "#     validation_rows = list(range(84500, 87050))\n",
    "#     validation_generator = BirdDataGenerator(csv_file=csv_file, use_rows=validation_rows, batch_size=128)\n",
    "    \n",
    "#     test_rows = list(range(81950, 84500))\n",
    "#     test_generator = BirdDataGenerator(csv_file=csv_file, use_rows=test_rows, batch_size=128)\n",
    "#     model.evaluate(x=test_generator)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8928421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 19:55:00.588995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-30 19:55:00.683392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-30 19:55:00.683908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-30 19:55:00.688718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-30 19:55:00.689258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-30 19:55:00.689709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-30 19:55:04.543873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-30 19:55:04.544469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-30 19:55:04.544498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-30 19:55:04.544991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-30 19:55:04.545057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3881 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 394272)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 510)               201079230 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,080,126\n",
      "Trainable params: 201,080,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(87050, 5)\n",
      "train/ABBOTTS BABBLER/001.jpg\n",
      "(1, 224, 224, 3)\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 19:55:06.120361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-03-30 19:55:12.253354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-03-30 19:55:15.371459: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-30 19:55:15.563781: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 665.74MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-30 19:55:15.617654: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.90GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-30 19:55:15.805790: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 665.74MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-30 19:55:15.805880: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-30 19:55:15.861493: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fe8b73964f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-30 19:55:15.861568: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti with Max-Q Design, Compute Capability 7.5\n",
      "2023-03-30 19:55:16.050048: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-30 19:55:16.124778: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-03-30 19:55:17.255289: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.90GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-30 19:55:17.319810: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-30 19:55:17.319911: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/640 [..............................] - ETA: 15:08 - loss: 10248.9629 - accuracy: 0.0018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 19:55:36.113126: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: IndexError: index 510 is out of bounds for axis 1 with size 510\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/tmp/ipykernel_17571/2315034495.py\", line 68, in __getitem__\n",
      "    y = tf.keras.utils.to_categorical(y, num_classes=510)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/np_utils.py\", line 74, in to_categorical\n",
      "    categorical[np.arange(n), y] = 1\n",
      "\n",
      "IndexError: index 510 is out of bounds for axis 1 with size 510\n",
      "\n",
      "\n",
      "2023-03-30 19:55:36.113252: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: IndexError: index 510 is out of bounds for axis 1 with size 510\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/tmp/ipykernel_17571/2315034495.py\", line 68, in __getitem__\n",
      "    y = tf.keras.utils.to_categorical(y, num_classes=510)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/np_utils.py\", line 74, in to_categorical\n",
      "    categorical[np.arange(n), y] = 1\n",
      "\n",
      "IndexError: index 510 is out of bounds for axis 1 with size 510\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "2023-03-30 19:55:36.113797: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: IndexError: index 510 is out of bounds for axis 1 with size 510\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/tmp/ipykernel_17571/2315034495.py\", line 68, in __getitem__\n",
      "    y = tf.keras.utils.to_categorical(y, num_classes=510)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/np_utils.py\", line 74, in to_categorical\n",
      "    categorical[np.arange(n), y] = 1\n",
      "\n",
      "IndexError: index 510 is out of bounds for axis 1 with size 510\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]]\n",
      "2023-03-30 19:55:36.113927: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: IndexError: index 510 is out of bounds for axis 1 with size 510\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/tmp/ipykernel_17571/2315034495.py\", line 68, in __getitem__\n",
      "    y = tf.keras.utils.to_categorical(y, num_classes=510)\n",
      "\n",
      "  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/np_utils.py\", line 74, in to_categorical\n",
      "    categorical[np.arange(n), y] = 1\n",
      "\n",
      "IndexError: index 510 is out of bounds for axis 1 with size 510\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  IndexError: index 510 is out of bounds for axis 1 with size 510\nTraceback (most recent call last):\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_17571/2315034495.py\", line 68, in __getitem__\n    y = tf.keras.utils.to_categorical(y, num_classes=510)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/np_utils.py\", line 74, in to_categorical\n    categorical[np.arange(n), y] = 1\n\nIndexError: index 510 is out of bounds for axis 1 with size 510\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  IndexError: index 510 is out of bounds for axis 1 with size 510\nTraceback (most recent call last):\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_17571/2315034495.py\", line 68, in __getitem__\n    y = tf.keras.utils.to_categorical(y, num_classes=510)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/np_utils.py\", line 74, in to_categorical\n    categorical[np.arange(n), y] = 1\n\nIndexError: index 510 is out of bounds for axis 1 with size 510\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_618]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mbird_cnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbirds.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m, in \u001b[0;36mbird_cnn_model\u001b[0;34m(csv_file)\u001b[0m\n\u001b[1;32m     15\u001b[0m train_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m81950\u001b[39m))\n\u001b[1;32m     16\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m BirdDataGenerator(csv_file\u001b[38;5;241m=\u001b[39mcsv_file, use_rows\u001b[38;5;241m=\u001b[39mtrain_rows, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(h)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  IndexError: index 510 is out of bounds for axis 1 with size 510\nTraceback (most recent call last):\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_17571/2315034495.py\", line 68, in __getitem__\n    y = tf.keras.utils.to_categorical(y, num_classes=510)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/np_utils.py\", line 74, in to_categorical\n    categorical[np.arange(n), y] = 1\n\nIndexError: index 510 is out of bounds for axis 1 with size 510\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  IndexError: index 510 is out of bounds for axis 1 with size 510\nTraceback (most recent call last):\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_17571/2315034495.py\", line 68, in __getitem__\n    y = tf.keras.utils.to_categorical(y, num_classes=510)\n\n  File \"/home/jer/miniconda3/envs/tf_env/lib/python3.9/site-packages/keras/utils/np_utils.py\", line 74, in to_categorical\n    categorical[np.arange(n), y] = 1\n\nIndexError: index 510 is out of bounds for axis 1 with size 510\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_618]"
     ]
    }
   ],
   "source": [
    "cnn_model = bird_cnn_model(\"birds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d1429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
